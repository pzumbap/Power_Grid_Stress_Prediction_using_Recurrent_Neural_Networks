{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Grid Stress Prediction using Recurrent Neural Networks\n",
    "## Implementing and Comparing Different RNN Architectures for Time Series Data\n",
    "### Pablo X Zumba\n",
    "\n",
    "This is classification task using RNNs (i.e., a sequence to value prediction). We have hourly power consumption of households for 12 hours. Based on this, we will determine whether the power grid is strained (1) or not (0). \n",
    "\n",
    "Therefore, use the columns from `Hour 0` to `Hour 11` to predict the `target` column in the `power.csv` data set.\n",
    "\n",
    "Don't forget to adjust the number of neurons in the input layers correctly. Otherwise, there could be errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 11:29:17.003030: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour 0</th>\n",
       "      <th>Hour 1</th>\n",
       "      <th>Hour 2</th>\n",
       "      <th>Hour 3</th>\n",
       "      <th>Hour 4</th>\n",
       "      <th>Hour 5</th>\n",
       "      <th>Hour 6</th>\n",
       "      <th>Hour 7</th>\n",
       "      <th>Hour 8</th>\n",
       "      <th>Hour 9</th>\n",
       "      <th>Hour 10</th>\n",
       "      <th>Hour 11</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.550633</td>\n",
       "      <td>2.523400</td>\n",
       "      <td>2.582333</td>\n",
       "      <td>2.541667</td>\n",
       "      <td>2.475733</td>\n",
       "      <td>2.476233</td>\n",
       "      <td>2.455800</td>\n",
       "      <td>2.447200</td>\n",
       "      <td>2.441733</td>\n",
       "      <td>3.146133</td>\n",
       "      <td>2.661733</td>\n",
       "      <td>2.576000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.596933</td>\n",
       "      <td>1.619567</td>\n",
       "      <td>2.473733</td>\n",
       "      <td>2.731133</td>\n",
       "      <td>2.431133</td>\n",
       "      <td>2.479667</td>\n",
       "      <td>1.690200</td>\n",
       "      <td>1.332133</td>\n",
       "      <td>1.375167</td>\n",
       "      <td>1.050900</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>2.651900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.534933</td>\n",
       "      <td>0.540467</td>\n",
       "      <td>0.575367</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>0.521900</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>1.426467</td>\n",
       "      <td>0.602067</td>\n",
       "      <td>0.547433</td>\n",
       "      <td>0.525067</td>\n",
       "      <td>1.270300</td>\n",
       "      <td>0.393767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.085867</td>\n",
       "      <td>0.651233</td>\n",
       "      <td>0.634600</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.646067</td>\n",
       "      <td>0.628400</td>\n",
       "      <td>0.611067</td>\n",
       "      <td>0.612533</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.606067</td>\n",
       "      <td>1.471867</td>\n",
       "      <td>0.834533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.310833</td>\n",
       "      <td>0.250933</td>\n",
       "      <td>0.277667</td>\n",
       "      <td>0.308633</td>\n",
       "      <td>0.610400</td>\n",
       "      <td>1.563533</td>\n",
       "      <td>1.421867</td>\n",
       "      <td>3.324400</td>\n",
       "      <td>3.207567</td>\n",
       "      <td>1.425433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hour 0    Hour 1    Hour 2    Hour 3    Hour 4    Hour 5    Hour 6  \\\n",
       "0  2.550633  2.523400  2.582333  2.541667  2.475733  2.476233  2.455800   \n",
       "1  1.596933  1.619567  2.473733  2.731133  2.431133  2.479667  1.690200   \n",
       "2  0.534933  0.540467  0.575367  0.526500  0.521900  0.565333  1.426467   \n",
       "3  1.085867  0.651233  0.634600  0.653000  0.646067  0.628400  0.611067   \n",
       "4  0.456000  0.286300  0.310833  0.250933  0.277667  0.308633  0.610400   \n",
       "\n",
       "     Hour 7    Hour 8    Hour 9   Hour 10   Hour 11  target  \n",
       "0  2.447200  2.441733  3.146133  2.661733  2.576000       1  \n",
       "1  1.332133  1.375167  1.050900  0.585900  2.651900       1  \n",
       "2  0.602067  0.547433  0.525067  1.270300  0.393767       0  \n",
       "3  0.612533  0.660100  0.606067  1.471867  0.834533       0  \n",
       "4  1.563533  1.421867  3.324400  3.207567  1.425433       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power = pd.read_csv('power.csv')\n",
    "\n",
    "power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1417, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 1000 days are for train\n",
    "train = power.iloc[:1000]\n",
    "\n",
    "# Remaining 417 days are for test\n",
    "test = power.iloc[-417:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Input and Target values\n",
    "\n",
    "The first 12 columns (hourly data) will be input to predict the last column (i.e., target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 12 columns (from 0 to 11) are inputs\n",
    "\n",
    "train_inputs = train.iloc[:,:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add one more dimension to make it ready for RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.55063333],\n",
       "        [2.5234    ],\n",
       "        [2.58233333],\n",
       "        ...,\n",
       "        [3.14613333],\n",
       "        [2.66173333],\n",
       "        [2.576     ]],\n",
       "\n",
       "       [[1.59693333],\n",
       "        [1.61956667],\n",
       "        [2.47373333],\n",
       "        ...,\n",
       "        [1.0509    ],\n",
       "        [0.5859    ],\n",
       "        [2.6519    ]],\n",
       "\n",
       "       [[0.53493333],\n",
       "        [0.54046667],\n",
       "        [0.57536667],\n",
       "        ...,\n",
       "        [0.52506667],\n",
       "        [1.2703    ],\n",
       "        [0.39376667]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.5426    ],\n",
       "        [0.79336667],\n",
       "        [0.70356667],\n",
       "        ...,\n",
       "        [1.8318    ],\n",
       "        [1.2689    ],\n",
       "        [0.35363333]],\n",
       "\n",
       "       [[0.4064    ],\n",
       "        [0.7657    ],\n",
       "        [0.3216    ],\n",
       "        ...,\n",
       "        [0.8938    ],\n",
       "        [0.7913    ],\n",
       "        [0.86173333]],\n",
       "\n",
       "       [[0.32603333],\n",
       "        [0.3344    ],\n",
       "        [0.28883333],\n",
       "        ...,\n",
       "        [1.36266667],\n",
       "        [1.54143333],\n",
       "        [1.4652    ]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an additional dimension for train\n",
    "\n",
    "train_x = np.array(train_inputs).reshape(1000,12,1)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last column is TARGET\n",
    "\n",
    "train_target = train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 12 columns are inputs\n",
    "\n",
    "test_inputs = test.iloc[:,:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 12, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an additional dimension for test\n",
    "\n",
    "test_x = np.array(test_inputs).reshape(417,12,1)\n",
    "\n",
    "test_x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last column is TARGET\n",
    "\n",
    "test_target = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dummy_clf.fit(train_x, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train Accuracy: 0.505\n"
     ]
    }
   ],
   "source": [
    "#Baseline Train Accuracy\n",
    "dummy_train_pred = dummy_clf.predict(train_x)\n",
    "\n",
    "baseline_train_acc = accuracy_score(train_target, dummy_train_pred)\n",
    "\n",
    "print('Baseline Train Accuracy: {}' .format(baseline_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.49640287769784175\n"
     ]
    }
   ],
   "source": [
    "#Baseline Test Accuracy\n",
    "dummy_test_pred = dummy_clf.predict(test_x)\n",
    "\n",
    "baseline_test_acc = accuracy_score(test_target, dummy_test_pred)\n",
    "\n",
    "print('Baseline Test Accuracy: {}' .format(baseline_test_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a normal (cross-sectional) NN\n",
    "\n",
    "This model assumes that the data is NOT a time-series data set. It treats the data as cross-sectional and the columns being independent of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 11:29:22.805694: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[12, 1]),\n",
    "    keras.layers.Dense(12, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 11ms/step - loss: 0.6368 - accuracy: 0.6360 - val_loss: 0.6373 - val_accuracy: 0.6043\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7110 - val_loss: 0.5791 - val_accuracy: 0.7098\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7380 - val_loss: 0.6450 - val_accuracy: 0.6139\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7520 - val_loss: 0.5273 - val_accuracy: 0.7026\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7600 - val_loss: 0.5317 - val_accuracy: 0.7026\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7460 - val_loss: 0.5159 - val_accuracy: 0.6882\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7520 - val_loss: 0.5318 - val_accuracy: 0.7434\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7510 - val_loss: 0.5310 - val_accuracy: 0.7362\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7540 - val_loss: 0.6158 - val_accuracy: 0.6811\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7600 - val_loss: 0.5147 - val_accuracy: 0.7074\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7630 - val_loss: 0.5245 - val_accuracy: 0.7602\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7610 - val_loss: 0.5501 - val_accuracy: 0.7098\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7600 - val_loss: 0.5320 - val_accuracy: 0.7170\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7540 - val_loss: 0.5489 - val_accuracy: 0.7338\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7720 - val_loss: 0.5483 - val_accuracy: 0.7170\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7510 - val_loss: 0.5275 - val_accuracy: 0.7146\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7720 - val_loss: 0.5684 - val_accuracy: 0.7218\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7400 - val_loss: 0.5282 - val_accuracy: 0.7410\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7700 - val_loss: 0.5287 - val_accuracy: 0.7194\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7630 - val_loss: 0.5136 - val_accuracy: 0.7170\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7680 - val_loss: 0.5100 - val_accuracy: 0.7266\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7770 - val_loss: 0.5133 - val_accuracy: 0.7338\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7700 - val_loss: 0.6213 - val_accuracy: 0.7122\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7650 - val_loss: 0.5586 - val_accuracy: 0.7194\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7760 - val_loss: 0.5196 - val_accuracy: 0.7530\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7720 - val_loss: 0.5201 - val_accuracy: 0.7074\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7730 - val_loss: 0.6105 - val_accuracy: 0.6859\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.5267 - val_accuracy: 0.7146\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7800 - val_loss: 0.5450 - val_accuracy: 0.7386\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7810 - val_loss: 0.5103 - val_accuracy: 0.7242\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7800 - val_loss: 0.5260 - val_accuracy: 0.7146\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7740 - val_loss: 0.5405 - val_accuracy: 0.7170\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7730 - val_loss: 0.5129 - val_accuracy: 0.7242\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7790 - val_loss: 0.5366 - val_accuracy: 0.7098\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7840 - val_loss: 0.5132 - val_accuracy: 0.7218\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7820 - val_loss: 0.5095 - val_accuracy: 0.7362\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7790 - val_loss: 0.5093 - val_accuracy: 0.7338\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7890 - val_loss: 0.5535 - val_accuracy: 0.7362\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7910 - val_loss: 0.5070 - val_accuracy: 0.7242\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7920 - val_loss: 0.5014 - val_accuracy: 0.7530\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7840 - val_loss: 0.5048 - val_accuracy: 0.7314\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7980 - val_loss: 0.5058 - val_accuracy: 0.7266\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7910 - val_loss: 0.5220 - val_accuracy: 0.7242\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7870 - val_loss: 0.5052 - val_accuracy: 0.7338\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7910 - val_loss: 0.5307 - val_accuracy: 0.7506\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7920 - val_loss: 0.4997 - val_accuracy: 0.7602\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7890 - val_loss: 0.5102 - val_accuracy: 0.7290\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8010 - val_loss: 0.5155 - val_accuracy: 0.7314\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.7900 - val_loss: 0.5189 - val_accuracy: 0.7458\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8000 - val_loss: 0.5163 - val_accuracy: 0.7362\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=50,\n",
    "                    validation_data=(test_x, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5163407921791077, 0.7362110018730164]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.52\n",
      "accuracy: 73.62%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple RNN with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.SimpleRNN(32, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 13ms/step - loss: 0.5760 - accuracy: 0.7020 - val_loss: 0.5558 - val_accuracy: 0.7242\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7310 - val_loss: 0.5855 - val_accuracy: 0.6930\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4897 - accuracy: 0.7510 - val_loss: 0.9441 - val_accuracy: 0.5635\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.7310 - val_loss: 0.5472 - val_accuracy: 0.7098\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7640 - val_loss: 0.5458 - val_accuracy: 0.7002\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7620 - val_loss: 0.5159 - val_accuracy: 0.7170\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7570 - val_loss: 0.6534 - val_accuracy: 0.6475\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4911 - accuracy: 0.7430 - val_loss: 0.5285 - val_accuracy: 0.7314\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7610 - val_loss: 0.6145 - val_accuracy: 0.6595\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7600 - val_loss: 0.5206 - val_accuracy: 0.7290\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7560 - val_loss: 0.5173 - val_accuracy: 0.7578\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=50,\n",
    "                    validation_data=(test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5172591805458069, 0.7577937841415405]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.52\n",
      "accuracy: 75.78%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predictions are probabilities.\n",
    "\n",
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rounding the probabilities determines 1 or 0\n",
    "\n",
    "np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[186,  24],\n",
       "       [ 77, 130]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target, np.round(predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple RNN with two or more layers (Deep RNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be careful: when stacking RNN layers, you have to set \"return_sequences\" to True. This enables the layer to send a \"sequence\" of values to the next layer -- jut like how it uses a sequence of values for training.**\n",
    "\n",
    "**Since the last layer is DENSE, it can't take sequence data. Therefore, you CANNOT return sequences from the previous layer. So, remove** `return_sequences` **from previous layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(24, return_sequences=True, input_shape=[n_steps, n_inputs] ),\n",
    "    keras.layers.SimpleRNN(24, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(24), \n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 3s 22ms/step - loss: 0.5932 - accuracy: 0.6840 - val_loss: 0.7807 - val_accuracy: 0.6139\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5571 - accuracy: 0.7180 - val_loss: 0.5610 - val_accuracy: 0.6978\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5304 - accuracy: 0.7380 - val_loss: 0.9165 - val_accuracy: 0.5588\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5420 - accuracy: 0.7310 - val_loss: 0.5466 - val_accuracy: 0.6978\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.7520 - val_loss: 0.5888 - val_accuracy: 0.6954\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4869 - accuracy: 0.7640 - val_loss: 0.5129 - val_accuracy: 0.7122\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4869 - accuracy: 0.7480 - val_loss: 0.5734 - val_accuracy: 0.7338\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4930 - accuracy: 0.7480 - val_loss: 0.5414 - val_accuracy: 0.7410\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4708 - accuracy: 0.7580 - val_loss: 0.6765 - val_accuracy: 0.6331\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4687 - accuracy: 0.7480 - val_loss: 0.4959 - val_accuracy: 0.7578\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4581 - accuracy: 0.7660 - val_loss: 0.5992 - val_accuracy: 0.5779\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4923 - accuracy: 0.7360 - val_loss: 0.5058 - val_accuracy: 0.7554\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4691 - accuracy: 0.7540 - val_loss: 0.5231 - val_accuracy: 0.7122\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4600 - accuracy: 0.7730 - val_loss: 0.5157 - val_accuracy: 0.7338\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4523 - accuracy: 0.7810 - val_loss: 0.5365 - val_accuracy: 0.7074\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5364943742752075, 0.7074340581893921]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.54\n",
      "accuracy: 70.74%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LSTM with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(24, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 3s 34ms/step - loss: 0.5881 - accuracy: 0.6850 - val_loss: 0.5543 - val_accuracy: 0.7290\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5104 - accuracy: 0.7420 - val_loss: 0.6199 - val_accuracy: 0.6811\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4863 - accuracy: 0.7440 - val_loss: 0.9323 - val_accuracy: 0.5683\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.7530 - val_loss: 0.5367 - val_accuracy: 0.7098\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4718 - accuracy: 0.7570 - val_loss: 0.5368 - val_accuracy: 0.7026\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4642 - accuracy: 0.7590 - val_loss: 0.5177 - val_accuracy: 0.7098\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7630 - val_loss: 0.5215 - val_accuracy: 0.7530\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4677 - accuracy: 0.7520 - val_loss: 0.5072 - val_accuracy: 0.7266\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.4641 - accuracy: 0.7540 - val_loss: 0.5620 - val_accuracy: 0.7194\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4645 - accuracy: 0.7540 - val_loss: 0.5026 - val_accuracy: 0.7602\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4568 - accuracy: 0.7620 - val_loss: 0.5073 - val_accuracy: 0.7698\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4657 - accuracy: 0.7540 - val_loss: 0.5342 - val_accuracy: 0.7074\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4585 - accuracy: 0.7680 - val_loss: 0.5159 - val_accuracy: 0.7266\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4543 - accuracy: 0.7680 - val_loss: 0.5144 - val_accuracy: 0.7674\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4513 - accuracy: 0.7750 - val_loss: 0.5299 - val_accuracy: 0.7194\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5298769474029541, 0.7194244861602783]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.53\n",
      "accuracy: 71.94%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LSTM with two or more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(32, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(32, return_sequences=True),\n",
    "    keras.layers.LSTM(32),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 6s 50ms/step - loss: 0.6202 - accuracy: 0.6620 - val_loss: 0.7729 - val_accuracy: 0.5683\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.5618 - accuracy: 0.7110 - val_loss: 0.6823 - val_accuracy: 0.6499\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5256 - accuracy: 0.7470 - val_loss: 1.0197 - val_accuracy: 0.5204\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.5424 - accuracy: 0.7320 - val_loss: 0.5767 - val_accuracy: 0.7050\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.4857 - accuracy: 0.7600 - val_loss: 0.5243 - val_accuracy: 0.7074\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.4658 - accuracy: 0.7570 - val_loss: 0.5120 - val_accuracy: 0.7098\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.4704 - accuracy: 0.7490 - val_loss: 0.5589 - val_accuracy: 0.7698\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.4694 - accuracy: 0.7460 - val_loss: 0.5101 - val_accuracy: 0.7746\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4601 - accuracy: 0.7430 - val_loss: 0.5525 - val_accuracy: 0.7074\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.4573 - accuracy: 0.7580 - val_loss: 0.5066 - val_accuracy: 0.7578\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.4539 - accuracy: 0.7650 - val_loss: 0.5275 - val_accuracy: 0.7362\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.4685 - accuracy: 0.7490 - val_loss: 0.6492 - val_accuracy: 0.7050\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.4557 - accuracy: 0.7730 - val_loss: 0.4966 - val_accuracy: 0.7266\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.4395 - accuracy: 0.7680 - val_loss: 0.5487 - val_accuracy: 0.7434\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.4369 - accuracy: 0.7810 - val_loss: 0.5618 - val_accuracy: 0.7146\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.4399 - accuracy: 0.7620 - val_loss: 0.5092 - val_accuracy: 0.7338\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.4328 - accuracy: 0.7870 - val_loss: 0.5680 - val_accuracy: 0.7170\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.4365 - accuracy: 0.7820 - val_loss: 0.5327 - val_accuracy: 0.7410\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5327463746070862, 0.7410072088241577]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.53\n",
      "accuracy: 74.10%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GRU with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(24, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(1, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 3s 20ms/step - loss: 7.7896 - accuracy: 0.4950 - val_loss: 7.6570 - val_accuracy: 0.5036\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7896 - accuracy: 0.4950 - val_loss: 7.6570 - val_accuracy: 0.5036\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7896 - accuracy: 0.4950 - val_loss: 7.6570 - val_accuracy: 0.5036\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7896 - accuracy: 0.4950 - val_loss: 7.6570 - val_accuracy: 0.5036\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.7896 - accuracy: 0.4950 - val_loss: 7.6570 - val_accuracy: 0.5036\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.7896 - accuracy: 0.4950 - val_loss: 7.6570 - val_accuracy: 0.5036\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.656989097595215, 0.5035971403121948]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 7.66\n",
      "accuracy: 50.36%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GRU with two or more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(6, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(6, return_sequences=True),\n",
    "    keras.layers.GRU(6),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 6s 46ms/step - loss: 0.6179 - accuracy: 0.6640 - val_loss: 0.5684 - val_accuracy: 0.7170\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.5254 - accuracy: 0.7340 - val_loss: 0.6260 - val_accuracy: 0.6811\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.5045 - accuracy: 0.7420 - val_loss: 0.8415 - val_accuracy: 0.5564\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.5058 - accuracy: 0.7400 - val_loss: 0.5441 - val_accuracy: 0.7074\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.4817 - accuracy: 0.7500 - val_loss: 0.5931 - val_accuracy: 0.7074\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4750 - accuracy: 0.7540 - val_loss: 0.5182 - val_accuracy: 0.7098\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4711 - accuracy: 0.7520 - val_loss: 0.5245 - val_accuracy: 0.7578\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.4753 - accuracy: 0.7430 - val_loss: 0.5132 - val_accuracy: 0.7626\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.4640 - accuracy: 0.7480 - val_loss: 0.6429 - val_accuracy: 0.6475\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4672 - accuracy: 0.7470 - val_loss: 0.5007 - val_accuracy: 0.7482\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4546 - accuracy: 0.7650 - val_loss: 0.5138 - val_accuracy: 0.7770\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4627 - accuracy: 0.7570 - val_loss: 0.5216 - val_accuracy: 0.7194\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4616 - accuracy: 0.7570 - val_loss: 0.4990 - val_accuracy: 0.7338\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4537 - accuracy: 0.7670 - val_loss: 0.5237 - val_accuracy: 0.7626\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.4525 - accuracy: 0.7700 - val_loss: 0.5247 - val_accuracy: 0.7194\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4579 - accuracy: 0.7590 - val_loss: 0.4965 - val_accuracy: 0.7458\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4479 - accuracy: 0.7710 - val_loss: 0.6434 - val_accuracy: 0.6571\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.4686 - accuracy: 0.7620 - val_loss: 0.5202 - val_accuracy: 0.7626\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.4458 - accuracy: 0.7700 - val_loss: 0.5586 - val_accuracy: 0.7002\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4420 - accuracy: 0.7820 - val_loss: 0.5012 - val_accuracy: 0.7722\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5011864304542542, 0.7721822261810303]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.50\n",
      "accuracy: 77.22%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 5, 10)             40        \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1, 20)             620       \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 1, 6)              648       \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 6)                 312       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,627\n",
      "Trainable params: 1,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=10, kernel_size=3, strides=2, padding=\"valid\", input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=3, strides=1, padding=\"valid\", dilation_rate=2),\n",
    "    keras.layers.LSTM(6, return_sequences=True),\n",
    "    keras.layers.LSTM(6),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 5s 28ms/step - loss: 0.6677 - accuracy: 0.6000 - val_loss: 0.6613 - val_accuracy: 0.5923\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5830 - accuracy: 0.7170 - val_loss: 0.6280 - val_accuracy: 0.6715\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5547 - accuracy: 0.7310 - val_loss: 0.8472 - val_accuracy: 0.5516\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.7410 - val_loss: 0.5796 - val_accuracy: 0.7122\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5296 - accuracy: 0.7570 - val_loss: 0.5830 - val_accuracy: 0.7002\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7410 - val_loss: 0.5534 - val_accuracy: 0.7002\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7350 - val_loss: 0.5845 - val_accuracy: 0.6906\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7370 - val_loss: 0.5648 - val_accuracy: 0.6954\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7350 - val_loss: 0.6223 - val_accuracy: 0.6355\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5108 - accuracy: 0.7510 - val_loss: 0.5388 - val_accuracy: 0.7074\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5065 - accuracy: 0.7510 - val_loss: 0.5722 - val_accuracy: 0.6882\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7280 - val_loss: 0.5685 - val_accuracy: 0.6954\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7540 - val_loss: 0.5421 - val_accuracy: 0.7314\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7540 - val_loss: 0.5619 - val_accuracy: 0.6882\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7520 - val_loss: 0.6062 - val_accuracy: 0.6882\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6061757206916809, 0.688249409198761]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.61\n",
      "accuracy: 68.82%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6e8d503ca3497b2311276643aea34fa4462df8f5c0c9e65d3521006dbd5b3aa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
